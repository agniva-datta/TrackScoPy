{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "396b6ed5",
   "metadata": {},
   "source": [
    "# Image Analysis Workspace\n",
    "\n",
    "\n",
    "### Import modules\n",
    "\n",
    "This notebook executes all functions of the image_analysis tools and allows the user to visualize and save the results. The convention for describing the workspace is as follows:\n",
    "\n",
    "$\\textbf{bold text}$  :    to describe path\n",
    "\n",
    "\n",
    "$\\color{blue}{blue \\hspace{0.2cm} text}$  :    to describe functions\n",
    "\n",
    "\n",
    "$\\color{red}{red \\hspace{0.2cm} text}$  :    to describe variables\n",
    "\n",
    "The user has to run the cell below to load the image analysis tools and the other necessary packages to load and read the raw image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d12ade-8682-48de-b2f0-058982e9e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trackscopy_fluorescence import image_analysis_tools as im\n",
    "from trackscopy_fluorescence import swim_mode_analysis_tools as sm\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tifffile as tf\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361e6fe5",
   "metadata": {},
   "source": [
    "## Specify path of raw-image\n",
    "\n",
    "The cell below loads the red channel and the green channel of the raw image. However the analysis works separately on the two channels, so the user can choose to load the two channels separately in any way. One has to only make sure that they are loaded as numpy arrays. \n",
    "\n",
    "In the cell below, an example syntax is provided where the raw image is not splitted and has only the red and green channels.\n",
    "\n",
    "The user has to update the path of raw image and the extensions. Then the user has to run the cell below to load it. \n",
    "\n",
    "Note that running the cell below will automatically create a sub-directory '$\\textbf{...[directory containing raw image]\\_results\\_image\\_analysis}$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6145312-52a7-489e-8aca-7204583b6a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARENT_DIRECTORY = '///'\n",
    "#SUB_DIRECTORY = '///'\n",
    "#DIRECTORY = os.path.join(PARENT_DIRECTORY,SUB_DIRECTORY)\n",
    "\n",
    "DIRECTORY = 'sample_data'\n",
    "\n",
    "FILE_NAME = 'motility_bacteria'\n",
    "\n",
    "ext = '.tif'\n",
    "ext_out = '.tif'\n",
    "\n",
    "full_filename = (FILE_NAME+ext)\n",
    "full_file =  os.path.join(DIRECTORY,full_filename)\n",
    "\n",
    "res_path = os.path.join(DIRECTORY,'results_image_analysis')\n",
    "\n",
    "if os.path.exists(res_path)!= True:\n",
    "    \n",
    "    os.mkdir(res_path)\n",
    "\n",
    "R_im = tf.imread(full_file)[:,0,:,:]\n",
    "G_im = tf.imread(full_file)[:,1,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c1ffd0",
   "metadata": {},
   "source": [
    "##  Perform image analysis for red and green channels\n",
    "\n",
    "The user has to check $\\textbf{'....\\\\TrackScoPy-main\\\\trackscopy\\_fluorescence\\\\default\\_parameters\\_image\\_analysis.py'}$ to check the parameters. Then the user has to run the two cells below to perform all the image analysis steps for both the red-channel and the green-channel. By default, it executes the following functions for both the channels:\n",
    "\n",
    "$\\color{blue}{background\\_correction( )}$ \n",
    "\n",
    "$\\color{blue}{segmentation( )}$  \n",
    "        \n",
    "$\\color{blue}{connected\\_regions\\_estimation( )}$ \n",
    "        \n",
    "$\\color{blue}{tracking( )}$\n",
    "\n",
    "$\\color{blue}{save\\_parameters( )}$\n",
    "\n",
    "The output 'data' (the user can change it freely to any name) will be an object (class) containing the following properties:\n",
    "\n",
    "$\\color{red}{background\\_corrected\\_image}$ :     Image object\n",
    "\n",
    "$\\color{red}{minimum\\_projection}$ :     Numpy array \n",
    "\n",
    "$\\color{red}{segmented\\_image}$ :     Image Object\n",
    "\n",
    "$\\color{red}{connected\\_position\\_list}$ :    Numpy array\n",
    "\n",
    "$\\color{red}{tracklist}$ :     List of Numpy arrays (each corresponding to a trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4623556d-45b0-4d05-aefe-2c05b694d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red channel\n",
    "\n",
    "data_red = im.Image_Analysis(R_im) ## initialize\n",
    "#data_red.blur_factor = 15 ## for the analysis of images provided in sample_data_drift except the calibration data, uncomment this line\n",
    "data_red.Analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57091c08-203e-44c4-a0df-a999d8e9f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Green channel\n",
    "\n",
    "data_green = im.Image_Analysis(G_im) ## initialize\n",
    "#data_green.blur_factor = 15 ## for the analysis of images provided in sample_data_drift except the calibration data, uncomment this line\n",
    "data_green.Analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e791b804",
   "metadata": {},
   "source": [
    "### Visualize the tracks in background\n",
    "\n",
    "The user can display the trajectories to observe if the analysis worked for both the red and green channels. The syntax in the two cells below show the trajectories from origin as well as in the background of the image selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03261ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_image_red = 2*data_red.background_corrected_image.im_array[-1]\n",
    "\n",
    "im.plot_tracks_with_background(data_red.smooth_tracks,background_image_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f405a831",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_image_green = 2*data_green.background_corrected_image.im_array[-1]\n",
    "\n",
    "im.plot_tracks_with_background(data_green.smooth_tracks,background_image_green)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484919b2",
   "metadata": {},
   "source": [
    "### note in case of error:\n",
    "\n",
    "Sometimes it might happen that one of the above steps, e.g., the tracking fails or the user is not satisfied with the result. Then, the user has to change the parameters and run the particular analysis step again. The user can have a look at the parameters that the analysis used, by the syntax $\\color{red}{data.parameter\\_dict}$.\n",
    "\n",
    "Then the user can change one or more particular parameters by the syntax $\\color{red}{data.[parameter] = [new \\hspace{0.2cm} value]}$, for example: let's say the tracking failed for blur_factor = 5 but the user has a feeling that it should work for blur_factor = 15, then the user has to update it by $\\color{red}{data.blur\\_factor = 15}$ and run the analysis again by modifying the parameter after the initialization step (as shown in the cells above as comments). \n",
    "\n",
    "#### To see options, what the user can do with an object, one can press \"tab\" after the syntax \"data_red.\" or \"data_green.\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946fe013-74b2-4c49-9f33-d457045b407b",
   "metadata": {},
   "source": [
    "## Classification of particles\n",
    "\n",
    "Now that we have the tracking data for each of the detected particles in both red and green channels, we can classify them based on certain conditions imposed on their trajectories. \n",
    "\n",
    "Although, this framework can be used in many instances, where different portions of the same particle are tracked in different color channels, in this notebook, we work with a very specfic case as discussed below.      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf74f4ef-132a-4ec6-9294-b09cccecc5ff",
   "metadata": {},
   "source": [
    "## Swim mode detection\n",
    "\n",
    "We consider the motility of a polarly flagellated soil bacterium $\\textit{Pseudomonas putida}$ which can swim in three different modes- $\\textbf{push}$ (where the bacterium rotates its flagellar bundle in the counter-clockwise direction to move forward along its axis, pointing from the flagellar bundle to cell body), $\\textbf{pull}$ (where the bacterium rotates its flagellar bundle in the clockwise direction to move backward with respect to its axial direction) and $\\textbf{wrap}$ (where the bacterium wraps its flagellar bundle around its cell body, in a screw-thread fashion to move). We track the cell body and the flagella of the bacteria in red and green channels respectively (as done above). Then, based on the positional alignment of the trajectories of the detected particles and their center of masses, we can classify each bacterium by their swim-modes. See the main text in the associated paper for further details of the detection algorithm:\n",
    "\n",
    "$\\textit{[Reference: paper (arXiv OR published\\ version)]}$\n",
    "\n",
    "The rest of the notebook is designed to execute the above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bc7aac-e9da-4edd-908e-f37f7a9cff64",
   "metadata": {},
   "source": [
    "### Specify calibration file (only for data with drift, skip cell below for data without drift)\n",
    "\n",
    "If the images are tracked in presence of a drift (flow), the user has to perform the rest of the analysis in the co-moving frame. So, the user will need the components of the flow velocity. \n",
    "\n",
    "One way of doing that will be to do a calibration experiment where the user can introduce some passive non-swimming cells/objects in the flow, and track them to obtain the mean and standard deviation of their velocities in the red channel. Then the user can generate the calibration file corresponding to this passive swimming data only from the red-channel. The function $\\color{blue}{im.generate\\_calibration( )}$ calculates the x and y components of the mean and the standard deviation of the velocities from the tracks in units of pixels/frames respectively. Then, it saves these four values as four rows in the text file $\\textbf{...\\\\[directory containing raw image]\\\\results\\_image\\_analysis\\\\calibration.txt}$. \n",
    "\n",
    "#### If the user wants to evaluate the calibration for the current file (calibration file), the commented two lines have to be uncommented. \n",
    "\n",
    "#### If the calibration file already exists, for the data with drift, it looks for the file and loads it.  In this case, make sure that the 1st and 3rd lines are commented out (default). \n",
    "\n",
    "#### Make sure to skip this step (one has to comment the whole cell out) if the data is without any flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5531c23-0d0f-415f-92b7-109e5d414570",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calibration = sm.generate_calibration(data_red.smooth_tracks)\n",
    "cal_file = os.path.join(res_path,'calibration.txt')\n",
    "#np.savetxt(cal_file,calibration)\n",
    "calibration = np.loadtxt(cal_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab4dad",
   "metadata": {},
   "source": [
    "Now, the user has to check $\\textbf{'....\\\\TrackScoPy-main\\\\trackscopy\\_fluorescence\\\\default\\_parameters\\_swim\\_mode\\_detection.py'}$ to check the parameters. Then the user has to run the cell below to perform the swim-mode detection analysis. By default, it executes the following functions:\n",
    "\n",
    "$\\color{blue}{Analysis( )}$ \n",
    "\n",
    "$\\color{blue}{sort\\_data( )}$  \n",
    "        \n",
    "$\\color{blue}{plot\\_tracks( )}$ \n",
    "\n",
    "$\\color{blue}{save\\_parameters( )}$\n",
    "\n",
    "The output 'analysis' (the user can change it freely to any name) will be an object (class) containing the following properties:\n",
    "\n",
    "$\\color{red}{data\\_with\\_id}$ :     a complete Pandas dataframe corresponding to all possible detected swim-modes\n",
    "\n",
    "$\\color{red}{sorted\\_data}$ :    a list of dataframes, each corresponding to a possible swimmer sorted by ID \n",
    "\n",
    "$\\color{red}{swimmers}$ :     a list of Objects, corresponding to the sorted data, each inhereting their corresponding dataframes\n",
    "\n",
    "$\\color{red}{parameter\\_dict}$ :     a dictionary of swim-mode analysis parameters\n",
    "\n",
    "If the user wants to save the plot from the $\\color{blue}{plot\\_tracks( )}$ function, the corresponding path of the image has to be specified as an input inside the function. The syntax would be $\\color{blue}{plot\\_tracks([path\\_to\\_image])}$  \n",
    "\n",
    "### Swimmer object\n",
    "\n",
    "As mentioned in the cell above, $\\color{red}{analysis.swimmers}$ corresponds to a list of Objects. The swimmer object consists of the following properties:\n",
    "\n",
    "$\\color{red}{dataframe}$ :   the dataframe inherited from the main analysis sorted by ID\n",
    "\n",
    "$\\color{red}{mean\\_speed}$ :    a float corresponding to the average velocity of the swimmer in microns/sec \n",
    "\n",
    "$\\color{red}{run\\_time}$ :     an integer corresponding to the run-time of the swimmer in frames\n",
    "\n",
    "$\\color{red}{episodes}$ :    a list of Objects, which are subsets of the swimmer sorted by a specific feature (swim-mode, orientation or flow)\n",
    "\n",
    "$\\color{red}{sorted\\_episodes\\_by}$ :    a string corresponding to the feature mentioned above\n",
    "\n",
    "And it contains the following function:\n",
    "\n",
    "$\\color{blue}{extract\\_episodes( )}$     default input: sort_by = 'SWIM-MODE', can be changed into 'FLOW' or 'ORIENTATION'\n",
    "\n",
    "#### Episode object\n",
    "\n",
    "As mentioned in the cell above, $\\color{red}{analysis.swimmer[i].episodes}$ corresponds to a list of Objects. The episode object consists of the following properties:\n",
    "\n",
    "$\\color{red}{dataframe}$ :   the dataframe inherited from the swimmer sorted by a specific feature (swim-mode, orientation or flow)\n",
    "\n",
    "$\\color{red}{mean\\_speed}$ :    a float corresponding to the average velocity of the episode in microns/sec \n",
    "\n",
    "$\\color{red}{run\\_time}$ :     an integer corresponding to the run-time of the episode in frames\n",
    "\n",
    "$\\color{red}{sorted\\_by}$ :    a string corresponding to the feature mentioned above by which it has been sorted from a given swimmer\n",
    "\n",
    "$\\color{red}{identity}$ :    a string corresponding to the value of the feature (e.g., type of swim-mode like 'pull')\n",
    "\n",
    "In case of data with drift, incorporate the calibration file (loaded in the previous step) by adding \"calibration=calibration\" in the Swim_Mode_Detection\" class. Otherwise, one has to leave it out (as commented below). And just like earlier, this will be an initialization step. The user can alter any of the parameters (see second comment) and run the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2983fe7-3e6c-4f58-aaad-0a27ae34aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = sm.Swim_Mode_Detection(data_red,data_green) ### initialize \n",
    "#analysis = sm.Swim_Mode_Detection(data_red,data_green,calibration=calibration) ### initialize \n",
    "#analysis.BACKGROUND_FACTOR = 0.05\n",
    "analysis.Analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48478853",
   "metadata": {},
   "source": [
    "The analysis automatically plots the trajectories classified by swim-mode detection. Blue corresponds to 'push', red corresponds to 'pull', green corresponds to 'wrap' and black corresponds to 'passive'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2181e8",
   "metadata": {},
   "source": [
    "## Check consistency of analysis results with observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da3e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(analysis.swimmers)):\n",
    "    print(f'Swimmer-{i}')\n",
    "    for episode in analysis.swimmers[i].episodes:\n",
    "        print(episode.identity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ebaab3-a3f7-4047-b16c-34bddf5b4de6",
   "metadata": {},
   "source": [
    "## Visualize the swim-mode detection over the frames of image\n",
    "\n",
    "The user can observe the motion of the pointing vector from the center of mass of the green signal to that of the red_signal by $\\color{blue}{analysis.write\\_arrow\\_image([path\\_to\\_video])}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446af73b-17e8-4a92-91d2-481176906aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arrow_path = os.path.join(res_path,f'{FILE_NAME}_arrow_image.tiff')\n",
    "#analysis.write_arrow_image(path=arrow_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b1cd13-8e61-4ed8-ba0a-a6d5317be99f",
   "metadata": {},
   "source": [
    "Also, the user can save an overlay of the segmented red and green channels along with the detected swim-modes by the function $\\color{blue}{analysis.write\\_swim\\_image([path\\_to\\_video])}$. \n",
    "\n",
    "However, this are optional. The cells below execute it, but it can be commented out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896464a9-febb-4667-857a-67c8622935fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "swim_path = os.path.join(res_path,f'{FILE_NAME}_swim_image.tiff')\n",
    "analysis.write_swim_image(path=swim_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a09b720",
   "metadata": {},
   "source": [
    "## Modifying default parameters and repeating analysis\n",
    "\n",
    "The analysis is executed using the default parameters. It is recommended not to change them unless the type of dataset is completely different (different mutants, different size of bacteria, etc.). Instead the user can modify one or more of the parameters of the analysis and re-run it to obtain different results. The cell below is an example how to do that. The user should uncomment and modify accordingly to do it.\n",
    "\n",
    "#### As stated earlier, for further options, what the user can do with the object, one can press \"tab\" after the syntax \"analysis.\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0f713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis.BAC_SIZE = 13\n",
    "#analysis.ARROW_LENGTH = 60\n",
    "\n",
    "#analysis.Analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf0565",
   "metadata": {},
   "source": [
    "## Modifying swim-mode analysis results\n",
    "\n",
    "Although, the analysis parameters are correct, the analysis might detect a few outliers which can be modified and updated by the user to improve the statistics. Below is an example syntax how to do it, where a few frames for the fourth swimmer are detected to be in passive swim-mode instead of wrap swim-mode. Or the user can also specify the indices explicitly and change the features as given by the ## syntax.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3578ce-4ddf-4a9a-ad80-c66487c4d58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = analysis.sorted_data[3]\n",
    "#df.loc[df['SWIM-MODE'] == 'passive', 'SWIM-MODE'] = 'wrap'\n",
    "#print(df)\n",
    "\n",
    "##df.loc[[1,2,3],'SWIM-MODE'] = 'push'\n",
    "\n",
    "#print(analysis.sorted_data[3])\n",
    "\n",
    "#analysis.extract_swimmers()\n",
    "#analysis.plot_tracks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d17b88",
   "metadata": {},
   "source": [
    "## Save Analysis Results as a pickle file\n",
    "\n",
    "Once the  analysis works as per the user's requirement after the automatic analysis and manual corrections (if required), the user can save the analysis results in two ways. The user can save the whole analysis containing the features of all the red and green channels as well as the swim-mode analysis results  as a $\\textbf{.pickle}$ file by the following syntax:\n",
    "\n",
    "$\\color{blue}{analysis.save([file name]})$\n",
    "\n",
    "This will be a large file, around 2 times the size of the raw_image. \n",
    "\n",
    "Otherwise, the user can save the parameters used for the red and green channel image analysis, parameters for the swim-mode detection along with the swim-mode detection analysis results only by the following syntax:\n",
    "\n",
    "$\\color{blue}{analysis.save\\_detection\\_results\\_only([file name]})$\n",
    "\n",
    "For both cases, the user should not forget to run the syntax $\\color{blue}{data.save\\_parameters( )}$ (especially after manually correcting the parameters in the middle of analysis) before the user saves the final file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3465b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = os.path.join(res_path,f'{FILE_NAME}_swim_mode_analysis.pickle')\n",
    "analysis.save_detection_results_only(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090df41e",
   "metadata": {},
   "source": [
    "## Save Analysis Results in a separate directory\n",
    "\n",
    "The user will have the option to save the analysis results in a separate directory \n",
    "\n",
    "$\\textbf{...\\\\[directory containing raw image]\\\\results\\_image\\_analysis\\\\[FILE\\_NAME]\\_individual\\_analysis}$\n",
    "\n",
    "inside which all dataframes will be saved individually as .csv files. Also, the parameters will be saved as a .txt file. One can uncomment to execute it. If the user is working with flow data, the orientation (ornt) has to be set to 'True'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ornt = True\n",
    "ornt = False\n",
    "analysis.save_results_individual(res_path,FILE_NAME,ORIENTATION=ornt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c5c945",
   "metadata": {},
   "source": [
    "## Analyse together a group of image files\n",
    "\n",
    "An example function is provided which executes all the steps as mentioned above. This function can be applied over a number of image files, as done in the next cell below. It iterates over a given directory to look for all sub-directories inside it, for each of which, it automatically generates the calibration file and analyzes the other substacks in that sub-directory. One can modify according to one's arrangement and nomenclature of the files and uncomment to execute it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea5a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def analyse_together(full_file,res_path,calibration):\n",
    "    \n",
    "    R_im = tf.imread(full_file)[:,0,:,:]\n",
    "    G_im = tf.imread(full_file)[:,1,:,:]\n",
    "\n",
    "    filename = full_file.split('.')[0].split('/')[-1]\n",
    "    \n",
    "    data_red = im.Image_Analysis(R_im) ## initialize\n",
    "    data_red.Analysis()\n",
    "            \n",
    "    data_green = im.Image_Analysis(G_im) ## initialize\n",
    "    data_green.Analysis()\n",
    "    \n",
    "    if len(calibration) != 0:\n",
    "        analysis = sm.Swim_Mode_Detection(data_red,data_green,calibration=calibration)\n",
    "    else:\n",
    "        analysis = sm.Swim_Mode_Detection(data_red,data_green)\n",
    "        \n",
    "    analysis.BAC_SIZE = 8\n",
    "\n",
    "    analysis.Analysis()\n",
    "    analysis.save_parameters()\n",
    "    pickle_file = os.path.join(res_path,f'{filename}_swim_mode_analysis.pickle')\n",
    "    analysis.save_detection_results_only(pickle_file)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''PARENT_DIRECTORY = '///\n",
    "\n",
    "res = 'analysis_result_collective'\n",
    "cal_filename = '00_calibration.tif'\n",
    "\n",
    "ext = '.tif'\n",
    "ext_out = '.tif'\n",
    "\n",
    "\n",
    "SUB_DIRECTORIES = [x for x in next(os.walk(PARENT_DIRECTORY), (None, [], None))[1] if x!=res]\n",
    "\n",
    "for SUB_DIRECTORY in SUB_DIRECTORIES:\n",
    "    \n",
    "    print(f'Sub-directory: {SUB_DIRECTORY}')\n",
    "    \n",
    "    DIRECTORY = os.path.join(PARENT_DIRECTORY,SUB_DIRECTORY)\n",
    "    res_path = os.path.join(DIRECTORY,'results_image_analysis')\n",
    "\n",
    "    if os.path.exists(res_path)!= True:\n",
    "        \n",
    "        os.mkdir(res_path)    \n",
    "    \n",
    "    FILE_NAMES = [x for x in next(os.walk(DIRECTORY), (None, None, []))[2] if x!= cal_filename and if x.split('.')[-1]==ext]\n",
    "    cal_file = os.path.join(DIRECTORY,cal_filename)\n",
    "    caltxt_file = os.path.join(res_path,'calibration.txt')\n",
    "    \n",
    "    if os.path.exists(cal_file) == True:\n",
    "        \n",
    "        print('Generating Calibration File')\n",
    "        \n",
    "        if os.path.exists(caltxt_file) == True:\n",
    "                calibration = np.loadtxt(caltxt_file)\n",
    "        else:\n",
    "            R_im = tf.imread(cal_file)[:,0,:,:]\n",
    "            data_red = im.Image_Analysis(R_im) ## initialize\n",
    "            data_red.Analysis()    \n",
    "            calib = sm.generate_calibration(data_red.smooth_tracks)\n",
    "            np.savetxt(caltxt_file,calib)\n",
    "            calibration = np.loadtxt(caltxt_file)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print('Calibration file not found')\n",
    "        \n",
    "        calibration = []\n",
    "            \n",
    "            \n",
    "    for FILE_NAME in tqdm(FILE_NAMES,desc='Analysing all substacks'):\n",
    "        \n",
    "        print(FILE_NAME)\n",
    "        \n",
    "        full_file =  os.path.join(DIRECTORY,FILE_NAME)\n",
    "\n",
    "        res_path = os.path.join(DIRECTORY,'results_image_analysis')\n",
    "\n",
    "        if os.path.exists(res_path)!= True:\n",
    "\n",
    "            os.mkdir(res_path)\n",
    "            \n",
    "        analyse_together(full_file,res_path,calibration)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80329a49-6cd0-4e10-bf9a-b32d6e29b7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
